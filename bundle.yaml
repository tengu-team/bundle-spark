series: xenial
applications:
  "hadoop-plugin":
    charm: "cs:hadoop-plugin-27"
  "hadoop-resourcemanager":
    charm: "cs:hadoop-resourcemanager-29"
    num_units: 1
    to:
      - "1"
  "hadoop-namenode":
    charm: "cs:hadoop-namenode-27"
    num_units: 1
    to:
      - "1"
  zeppelin:
    charm: "cs:zeppelin-28"
    expose: true
    num_units: 1
    to:
      - "0"
  spark:
    charm: "cs:spark-52"
    num_units: 1
    options:
      spark_bench_enabled: true
    to:
      - "0"
  "hadoop-slave":
    charm: "cs:hadoop-slave-28"
    num_units: 1
    to:
      - "0"
  "writedata":
    charm: "/home/sebastien/qrama/charms/xenial/spark-job"
    options:
      job_location: "https://raw.githubusercontent.com/Qrama/spark-bundle/master/jobs/writedata.py"
  "transformdata":
    charm: "/home/sebastien/qrama/charms/xenial/spark-job"
    options:
      job_location: "https://raw.githubusercontent.com/Qrama/spark-bundle/master/jobs/transformdata.py"
relations:
  - - "hadoop-namenode:datanode"
    - "hadoop-slave:namenode"
  - - "hadoop-plugin:namenode"
    - "hadoop-namenode:namenode"
  - - "zeppelin:hadoop"
    - "hadoop-plugin:hadoop-plugin"
  - - "hadoop-namenode:namenode"
    - "hadoop-resourcemanager:namenode"
  - - "zeppelin:spark"
    - "spark:client"
  - - "hadoop-resourcemanager:nodemanager"
    - "hadoop-slave:resourcemanager"
  - - "hadoop-plugin:resourcemanager"
    - "hadoop-resourcemanager:resourcemanager"
  - - "writedata:spark"
    - "spark:client"
  - - "transformdata:spark"
    - "spark:client"
machines:
  "0":
    series: xenial
    constraints: "arch=amd64 cpu-cores=1 cpu-power=138 mem=1700 root-disk=10240"
  "1":
    series: xenial
    constraints: "arch=amd64 cpu-cores=1 cpu-power=138 mem=1700 root-disk=10240"
